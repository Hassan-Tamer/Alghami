{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sohailelganagy7372/music-genre-classification-using-cnn?scriptVersionId=144205769\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport scipy\nimport cv2\nimport os\nimport pickle\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow import keras\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:54:22.490597Z","iopub.execute_input":"2023-09-25T16:54:22.491022Z","iopub.status.idle":"2023-09-25T16:54:30.442237Z","shell.execute_reply.started":"2023-09-25T16:54:22.490908Z","shell.execute_reply":"2023-09-25T16:54:30.441222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport librosa\nimport zipfile\n\nfrom tensorflow.keras.preprocessing import image\ndef load_images_from_path(path, label):\n    images = []\n    labels = []\n\n    for file in os.listdir(path):\n        try:\n            images.append(image.img_to_array(image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n            labels.append((label))\n        except Exception as e:\n            print(\"Error loading file:\")\n            print(\"Error message:\")\n        \n        \n    return images, labels\n\ndef show_images(images):\n    fig, axes = plt.subplots(1, 8, figsize=(20, 20), subplot_kw={'xticks': [], 'yticks': []})\n\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(images[i] / 255)\n        \ni=0\ndata = []\nlabels=[]\nx = []\ny = []\nfor genre in os.listdir(\"/kaggle/input/photoes/images_original\"):\n    genre_path = os.path.join(\"/kaggle/input/photoes/images_original\", genre)\n    file_count = 0\n    images=[]\n    #file_path = os.path.join(genre_path, file)\n    images, labels = load_images_from_path(genre_path, i)\n    #show_images(images)\n    x += images\n    y += labels\n    i=i+1\nprint(np.array(y).shape)\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.15, random_state=0)\n\nx_train_norm = np.array(x_train) / 255\nx_test_norm = np.array(x_test) / 255\n\ny_train_encoded = to_categorical(y_train)\ny_test_encoded = to_categorical(y_test)\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx_train_norm = preprocess_input(np.array(x_train))\nx_test_norm = preprocess_input(np.array(x_test))\n\ntrain_features = base_model.predict(x_train_norm)\ntest_features = base_model.predict(x_test_norm)\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nacc_per_fold = []\nloss_per_fold = []\nbatch_size = 50\nimg_width, img_height, img_num_channels = 224, 224, 3\nno_epochs = 40\nverbosity = 1\nnum_folds = 8\nmax=0\n# Merge inputs and targets\ninputs = np.concatenate((train_features, test_features), axis=0)\ntargets = np.concatenate((y_train_encoded, y_test_encoded), axis=0)\nnum_folds = 8\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)\n\n# K-fold Cross Validation model evaluation\nfold_no = 1\nbestfold1=0\nbestmodel1=0\nbestX_train1=0\nbestY_train1=0\nbestX_test1=0\nbestY_test1=0\nbestscore=0\nwhile(int(bestscore)<70):\n    for train, test in kfold.split(inputs, targets):\n\n\n\n      # Define the model architecture\n        model = Sequential()\n        model.add(Flatten(input_shape=train_features.shape[1:]))\n        model.add(Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n        model.add(Dropout(0.2))\n        model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n        model.add(Dropout(0.2))\n        model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n        model.add(Dropout(0.2))\n        model.add(BatchNormalization())\n        model.add(Dense(10, activation='softmax', kernel_regularizer=keras.regularizers.l2(0.001)))\n\n      # Compile the model\n        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\n\n      # Generate a print\n        print('------------------------------------------------------------------------')\n        print(f'Training for fold {fold_no} ...')\n\n      # Fit data to model\n        history = model.fit(inputs[train], targets[train],\n                  batch_size=batch_size,\n                  epochs=no_epochs,\n                  verbose=0)\n      # Generate generalization metrics\n        scores = model.evaluate(inputs[test], targets[test], verbose=0)\n        print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n        acc_per_fold.append(scores[1] * 100)\n        loss_per_fold.append(scores[0])\n        if((scores[1]*100) > max):\n            max=(scores[1]*100)\n            bestmodel1=model\n            bestX_train1=inputs[train]\n            bestY_train1=targets[train]\n            bestX_test1=inputs[test]\n            bestY_test1=targets[test]\n            bestfold1=fold_no\n            bestscore=scores[1] * 100\n      # Increase fold number\n        fold_no = fold_no + 1\n        print(\"best fold is\",bestfold1)\n\nbestmodel1.save(\"myModel.h5\")\n# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T16:54:35.579187Z","iopub.execute_input":"2023-09-25T16:54:35.579511Z","iopub.status.idle":"2023-09-25T16:57:45.156255Z","shell.execute_reply.started":"2023-09-25T16:54:35.579474Z","shell.execute_reply":"2023-09-25T16:57:45.155331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bestmodel1.evaluate(bestX_test1,bestY_test1)\npred=bestmodel1.predict(bestX_test1)\narr2=[]\narr3=[]\nfor i in range(len(pred)):\n    arr=np.array(pred[i])\n    arr2.append(arr.argmax())\nfor i in range(len(pred)):\n    arr=np.array(bestY_test1[i])\n    arr3.append(arr.argmax())\nprint(\"predictions\",arr2)\nprint(\"original\",arr3)\ndef accuracy(y_true, y_pred):\n    c=0\n    for i in range(len(y_pred)):\n        if(y_pred[i]==y_true[i]):\n            c=c+1\n    accuracy=c/len(y_pred) \n    return accuracy * 100\nprint(accuracy(arr2,arr3))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T14:04:33.133756Z","iopub.execute_input":"2023-09-25T14:04:33.134142Z","iopub.status.idle":"2023-09-25T14:04:33.453327Z","shell.execute_reply.started":"2023-09-25T14:04:33.134104Z","shell.execute_reply":"2023-09-25T14:04:33.451565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport librosa\nimport zipfile\n\nfrom tensorflow.keras.preprocessing import image\ndef load_images_from_path(path, label):\n    images = []\n    labels = []\n\n    for file in os.listdir(path):\n        try:\n            images.append(image.img_to_array(image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n            labels.append((label))\n        except Exception as e:\n            print(\"Error loading file:\")\n            print(\"Error message:\")\n        \n        \n    return images, labels\n\ndef show_images(images):\n    fig, axes = plt.subplots(1, 8, figsize=(20, 20), subplot_kw={'xticks': [], 'yticks': []})\n\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(images[i] / 255)\n        \ni=0\ndata = []\nlabels=[]\nx = []\ny = []\nfor genre in os.listdir(\"/kaggle/input/chromagram/chromagram\"):\n    genre_path = os.path.join(\"/kaggle/input/chromagram/chromagram\", genre)\n    file_count = 0\n    images=[]\n    #file_path = os.path.join(genre_path, file)\n    images, labels = load_images_from_path(genre_path, i)\n    #show_images(images)\n    x += images\n    y += labels\n    i=i+1\nprint(np.array(y).shape)\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.15, random_state=0)\n\nx_train_norm = np.array(x_train) / 255\nx_test_norm = np.array(x_test) / 255\n\ny_train_encoded = to_categorical(y_train)\ny_test_encoded = to_categorical(y_test)\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx_train_norm = preprocess_input(np.array(x_train))\nx_test_norm = preprocess_input(np.array(x_test))\n\ntrain_features = base_model.predict(x_train_norm)\ntest_features = base_model.predict(x_test_norm)\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nacc_per_fold = []\nloss_per_fold = []\nbatch_size = 50\nimg_width, img_height, img_num_channels = 224, 224, 3\nno_epochs = 40\nverbosity = 1\nnum_folds = 8\nmax=0\n# Merge inputs and targets\ninputs = np.concatenate((train_features, test_features), axis=0)\ntargets = np.concatenate((y_train_encoded, y_test_encoded), axis=0)\nnum_folds = 8\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)\n\n# K-fold Cross Validation model evaluation\nfold_no = 1\nbestfold2=0\nbestmodel2=0\nbestX_train2=0\nbestY_train2=0\nbestX_test2=0\nbestY_test2=0\nfor train, test in kfold.split(inputs, targets):\n    \n    \n\n  # Define the model architecture\n    model = Sequential()\n    model.add(Flatten(input_shape=train_features.shape[1:]))\n    model.add(Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n    model.add(Dropout(0.2))\n    model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n    model.add(Dropout(0.2))\n    model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n    model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n    model.add(Dense(10, activation='softmax', kernel_regularizer=keras.regularizers.l2(0.001)))\n\n  # Compile the model\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\n\n  # Generate a print\n    print('------------------------------------------------------------------------')\n    print(f'Training for fold {fold_no} ...')\n    from tensorflow.keras.callbacks import EarlyStopping\n\n    early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min')\n  # Fit data to model\n    history = model.fit(inputs[train], targets[train],\n              batch_size=batch_size,\n              epochs=no_epochs,\n              steps_per_epoch=800,\n              verbose=0, callbacks=[early_stopping])\n  # Generate generalization metrics\n    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n    acc_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0])\n    if((scores[1]*100) > max):\n        max=(scores[1]*100)\n        bestmodel2=model\n        bestX_train2=inputs[train]\n        bestY_train2=targets[train]\n        bestX_test2=inputs[test]\n        bestY_test2=targets[test]\n        bestfold2=fold_no\n  # Increase fold number\n    fold_no = fold_no + 1\n    print(\"best fold is\",bestfold2)\n\n# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T14:04:33.456044Z","iopub.execute_input":"2023-09-25T14:04:33.456577Z","iopub.status.idle":"2023-09-25T14:07:38.958595Z","shell.execute_reply.started":"2023-09-25T14:04:33.456535Z","shell.execute_reply":"2023-09-25T14:07:38.957624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bestmodel2.evaluate(bestX_test2,bestY_test2)\npred=bestmodel2.predict(bestX_test2)\narr2=[]\narr3=[]\nfor i in range(len(pred)):\n    arr=np.array(pred[i])\n    arr2.append(arr.argmax())\nfor i in range(len(pred)):\n    arr=np.array(bestY_test2[i])\n    arr3.append(arr.argmax())\nprint(\"predictions\",arr2)\nprint(\"original\",arr3)\ndef accuracy(y_true, y_pred):\n    c=0\n    for i in range(len(y_pred)):\n        if(y_pred[i]==y_true[i]):\n            c=c+1\n    accuracy=c/len(y_pred) \n    return accuracy * 100\nprint(accuracy(arr2,arr3))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T14:07:38.960381Z","iopub.execute_input":"2023-09-25T14:07:38.960693Z","iopub.status.idle":"2023-09-25T14:07:39.217992Z","shell.execute_reply.started":"2023-09-25T14:07:38.960651Z","shell.execute_reply":"2023-09-25T14:07:39.215873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport librosa\nimport zipfile\n\nfrom tensorflow.keras.preprocessing import image\ndef load_images_from_path(path, label):\n    images = []\n    labels = []\n\n    for file in os.listdir(path):\n        try:\n            images.append(image.img_to_array(image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n            labels.append((label))\n        except Exception as e:\n            print(\"Error loading file:\")\n            print(\"Error message:\")\n        \n        \n    return images, labels\n\ndef show_images(images):\n    fig, axes = plt.subplots(1, 8, figsize=(20, 20), subplot_kw={'xticks': [], 'yticks': []})\n\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(images[i] / 255)\n        \ni=0\ndata = []\nlabels=[]\nx = []\ny = []\nfor genre in os.listdir(\"/kaggle/input/tempogram/tempogram\"):\n    genre_path = os.path.join(\"/kaggle/input/tempogram/tempogram\", genre)\n    file_count = 0\n    images=[]\n    #file_path = os.path.join(genre_path, file)\n    images, labels = load_images_from_path(genre_path, i)\n    #show_images(images)\n    x += images\n    y += labels\n    i=i+1\nprint(np.array(y).shape)\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.15, random_state=0)\n\nx_train_norm = np.array(x_train) / 255\nx_test_norm = np.array(x_test) / 255\n\ny_train_encoded = to_categorical(y_train)\ny_test_encoded = to_categorical(y_test)\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx_train_norm = preprocess_input(np.array(x_train))\nx_test_norm = preprocess_input(np.array(x_test))\n\ntrain_features = base_model.predict(x_train_norm)\ntest_features = base_model.predict(x_test_norm)\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nacc_per_fold = []\nloss_per_fold = []\nbatch_size = 50\nimg_width, img_height, img_num_channels = 224, 224, 3\nno_epochs = 40\nverbosity = 1\nnum_folds = 8\nmax=0\n# Merge inputs and targets\ninputs = np.concatenate((train_features, test_features), axis=0)\ntargets = np.concatenate((y_train_encoded, y_test_encoded), axis=0)\nnum_folds = 8\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)\n\n# K-fold Cross Validation model evaluation\nfold_no = 1\nbestfold3=0\nbestmodel3=0\nbestX_train3=0\nbestY_train3=0\nbestX_test3=0\nbestY_test3=0\nfor train, test in kfold.split(inputs, targets):\n    \n    \n\n  # Define the model architecture\n    model = Sequential()\n    model.add(Flatten(input_shape=train_features.shape[1:]))\n    model.add(Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n    model.add(Dropout(0.2))\n    model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n    model.add(Dropout(0.2))\n    model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n    model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n    model.add(Dense(10, activation='softmax', kernel_regularizer=keras.regularizers.l2(0.001)))\n\n  # Compile the model\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\n\n  # Generate a print\n    print('------------------------------------------------------------------------')\n    print(f'Training for fold {fold_no} ...')\n\n    from tensorflow.keras.callbacks import EarlyStopping\n\n    early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min')\n  # Fit data to model\n    history = model.fit(inputs[train], targets[train],\n              batch_size=batch_size,\n              epochs=no_epochs,\n              steps_per_epoch=800,\n              verbose=0, callbacks=[early_stopping])\n  # Generate generalization metrics\n    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n    acc_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0])\n    if((scores[1]*100) > max):\n        max=(scores[1]*100)\n        bestmodel3=model\n        bestX_train3=inputs[train]\n        bestY_train3=targets[train]\n        bestX_test3=inputs[test]\n        bestY_test3=targets[test]\n        bestfold3=fold_no\n  # Increase fold number\n    fold_no = fold_no + 1\n    print(\"best fold is\",bestfold3)\n\n# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T14:07:39.220378Z","iopub.execute_input":"2023-09-25T14:07:39.220888Z","iopub.status.idle":"2023-09-25T14:10:46.468192Z","shell.execute_reply.started":"2023-09-25T14:07:39.220846Z","shell.execute_reply":"2023-09-25T14:10:46.467337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bestmodel3.evaluate(bestX_test3,bestY_test3)\npred=bestmodel3.predict(bestX_test3)\narr2=[]\narr3=[]\nfor i in range(len(pred)):\n    arr=np.array(pred[i])\n    arr2.append(arr.argmax())\nfor i in range(len(pred)):\n    arr=np.array(bestY_test3[i])\n    arr3.append(arr.argmax())\nprint(\"predictions\",arr2)\nprint(\"original\",arr3)\ndef accuracy(y_true, y_pred):\n    c=0\n    for i in range(len(y_pred)):\n        if(y_pred[i]==y_true[i]):\n            c=c+1\n    accuracy=c/len(y_pred) \n    return accuracy * 100\nprint(accuracy(arr2,arr3))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T14:10:46.471081Z","iopub.execute_input":"2023-09-25T14:10:46.471363Z","iopub.status.idle":"2023-09-25T14:10:46.71843Z","shell.execute_reply.started":"2023-09-25T14:10:46.471327Z","shell.execute_reply":"2023-09-25T14:10:46.717173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport librosa\nimport zipfile\n\nfrom tensorflow.keras.preprocessing import image\ndef load_images_from_path(path, label):\n    images = []\n    labels = []\n\n    for file in os.listdir(path):\n        try:\n            images.append(image.img_to_array(image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n            labels.append((label))\n        except Exception as e:\n            print(\"Error loading file:\")\n            print(\"Error message:\")\n        \n        \n    return images, labels\n\ndef show_images(images):\n    fig, axes = plt.subplots(1, 8, figsize=(20, 20), subplot_kw={'xticks': [], 'yticks': []})\n\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(images[i] / 255)\n        \ni=0\ndata = []\nlabels=[]\nx = []\ny = []\nfor genre in os.listdir(\"/kaggle/input/spectral-contrast/spectral contrast\"):\n    genre_path = os.path.join(\"/kaggle/input/spectral-contrast/spectral contrast\", genre)\n    file_count = 0\n    images=[]\n    #file_path = os.path.join(genre_path, file)\n    images, labels = load_images_from_path(genre_path, i)\n    #show_images(images)\n    x += images\n    y += labels\n    i=i+1\nprint(np.array(y).shape)\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.15, random_state=0)\n\nx_train_norm = np.array(x_train) / 255\nx_test_norm = np.array(x_test) / 255\n\ny_train_encoded = to_categorical(y_train)\ny_test_encoded = to_categorical(y_test)\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx_train_norm = preprocess_input(np.array(x_train))\nx_test_norm = preprocess_input(np.array(x_test))\n\ntrain_features = base_model.predict(x_train_norm)\ntest_features = base_model.predict(x_test_norm)\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nacc_per_fold = []\nloss_per_fold = []\nbatch_size = 50\nimg_width, img_height, img_num_channels = 224, 224, 3\nno_epochs = 40\nverbosity = 1\nnum_folds = 8\nmax=0\n# Merge inputs and targets\ninputs = np.concatenate((train_features, test_features), axis=0)\ntargets = np.concatenate((y_train_encoded, y_test_encoded), axis=0)\nnum_folds = 8\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)\n\n# K-fold Cross Validation model evaluation\nfold_no = 1\nbestfold4=0\nbestmodel4=0\nbestX_train4=0\nbestY_train4=0\nbestX_test4=0\nbestY_test4=0\nfor train, test in kfold.split(inputs, targets):\n    \n    \n\n  # Define the model architecture\n    model = Sequential()\n    model.add(Flatten(input_shape=train_features.shape[1:]))\n    model.add(Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n    model.add(Dropout(0.2))\n    model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n    model.add(Dropout(0.2))\n    model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n    model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n    model.add(Dense(10, activation='softmax', kernel_regularizer=keras.regularizers.l2(0.001)))\n\n  # Compile the model\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\n\n  # Generate a print\n    print('------------------------------------------------------------------------')\n    print(f'Training for fold {fold_no} ...')\n    from tensorflow.keras.callbacks import EarlyStopping\n\n    early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min')\n  # Fit data to model\n    history = model.fit(inputs[train], targets[train],\n              batch_size=batch_size,\n              epochs=no_epochs,\n              steps_per_epoch=800,\n              verbose=0, callbacks=[early_stopping])\n  # Generate generalization metrics\n    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n    acc_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0])\n    if((scores[1]*100) > max):\n        max=(scores[1]*100)\n        bestmodel4=model\n        bestX_train4=inputs[train]\n        bestY_train4=targets[train]\n        bestX_test4=inputs[test]\n        bestY_test4=targets[test]\n        bestfold4=fold_no\n  # Increase fold number\n    fold_no = fold_no + 1\n    print(\"best fold is\",bestfold4)\n\n# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T14:10:46.720014Z","iopub.execute_input":"2023-09-25T14:10:46.720463Z","iopub.status.idle":"2023-09-25T14:13:52.181376Z","shell.execute_reply.started":"2023-09-25T14:10:46.720421Z","shell.execute_reply":"2023-09-25T14:13:52.180492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bestmodel4.evaluate(bestX_test4,bestY_test4)\npred=bestmodel4.predict(bestX_test4)\narr2=[]\narr3=[]\nfor i in range(len(pred)):\n    arr=np.array(pred[i])\n    arr2.append(arr.argmax())\nfor i in range(len(pred)):\n    arr=np.array(bestY_test4[i])\n    arr3.append(arr.argmax())\nprint(\"predictions\",arr2)\nprint(\"original\",arr3)\ndef accuracy(y_true, y_pred):\n    c=0\n    for i in range(len(y_pred)):\n        if(y_pred[i]==y_true[i]):\n            c=c+1\n    accuracy=c/len(y_pred) \n    return accuracy * 100\nprint(accuracy(arr2,arr3))","metadata":{"execution":{"iopub.status.busy":"2023-09-25T14:13:52.183129Z","iopub.execute_input":"2023-09-25T14:13:52.183436Z","iopub.status.idle":"2023-09-25T14:13:52.439242Z","shell.execute_reply.started":"2023-09-25T14:13:52.183396Z","shell.execute_reply":"2023-09-25T14:13:52.438647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport librosa\nimport zipfile\n\nfrom tensorflow.keras.preprocessing import image\ndef load_images_from_path(path, label):\n    images = []\n    labels = []\n\n    for file in os.listdir(path):\n        try:\n            images.append(image.img_to_array(image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n            labels.append((label))\n        except Exception as e:\n            print(\"Error loading file:\")\n            print(\"Error message:\")\n        \n        \n    return images, labels\n\ndef show_images(images):\n    fig, axes = plt.subplots(1, 8, figsize=(20, 20), subplot_kw={'xticks': [], 'yticks': []})\n\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(images[i] / 255)\n        \ni=0\ndata = []\nlabels=[]\nx = []\ny = []\nfor genre in os.listdir(\"/kaggle/input/tonnetz/tonnetz\"):\n    genre_path = os.path.join(\"/kaggle/input/tonnetz/tonnetz\", genre)\n    file_count = 0\n    images=[]\n    #file_path = os.path.join(genre_path, file)\n    images, labels = load_images_from_path(genre_path, i)\n    #show_images(images)\n    x += images\n    y += labels\n    i=i+1\nprint(np.array(y).shape)\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.15, random_state=0)\n\nx_train_norm = np.array(x_train) / 255\nx_test_norm = np.array(x_test) / 255\n\ny_train_encoded = to_categorical(y_train)\ny_test_encoded = to_categorical(y_test)\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx_train_norm = preprocess_input(np.array(x_train))\nx_test_norm = preprocess_input(np.array(x_test))\n\ntrain_features = base_model.predict(x_train_norm)\ntest_features = base_model.predict(x_test_norm)\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nacc_per_fold = []\nloss_per_fold = []\nbatch_size = 50\nimg_width, img_height, img_num_channels = 224, 224, 3\nno_epochs = 40\nverbosity = 1\nnum_folds = 8\nmax=0\n# Merge inputs and targets\ninputs = np.concatenate((train_features, test_features), axis=0)\ntargets = np.concatenate((y_train_encoded, y_test_encoded), axis=0)\nnum_folds = 8\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)\n\n# K-fold Cross Validation model evaluation\nfold_no = 1\nbestfold5=0\nbestmodel5=0\nbestX_train5=0\nbestY_train5=0\nbestX_test5=0\nbestY_test5=0\nfor train, test in kfold.split(inputs, targets):\n    \n    \n\n  # Define the model architecture\n    model = Sequential()\n    model.add(Flatten(input_shape=train_features.shape[1:]))\n    model.add(Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n    model.add(Dropout(0.2))\n    model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n    model.add(Dropout(0.2))\n    model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n    model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n    model.add(Dense(10, activation='softmax', kernel_regularizer=keras.regularizers.l2(0.001)))\n\n  # Compile the model\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\n\n  # Generate a print\n    print('------------------------------------------------------------------------')\n    print(f'Training for fold {fold_no} ...')\n    from tensorflow.keras.callbacks import EarlyStopping\n\n    early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min')\n  # Fit data to model\n    history = model.fit(inputs[train], targets[train],\n              batch_size=batch_size,\n              epochs=no_epochs,\n              steps_per_epoch=800,\n              verbose=0, callbacks=[early_stopping])\n  # Generate generalization metrics\n    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n    acc_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0])\n    if((scores[1]*100) > max):\n        max=(scores[1]*100)\n        bestmodel5=model\n        bestX_train5=inputs[train]\n        bestY_train5=targets[train]\n        bestX_test5=inputs[test]\n        bestY_test5=targets[test]\n        bestfold5=fold_no\n  # Increase fold number\n    fold_no = fold_no + 1\n    print(\"best fold is\",bestfold5)\n\n# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T14:13:52.442957Z","iopub.execute_input":"2023-09-25T14:13:52.443358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bestmodel5.evaluate(bestX_test5,bestY_test5)\npred=bestmodel5.predict(bestX_test5)\narr2=[]\narr3=[]\nfor i in range(len(pred)):\n    arr=np.array(pred[i])\n    arr2.append(arr.argmax())\nfor i in range(len(pred)):\n    arr=np.array(bestY_test5[i])\n    arr3.append(arr.argmax())\nprint(\"predictions\",arr2)\nprint(\"original\",arr3)\ndef accuracy(y_true, y_pred):\n    c=0\n    for i in range(len(y_pred)):\n        if(y_pred[i]==y_true[i]):\n            c=c+1\n    accuracy=c/len(y_pred) \n    return accuracy * 100\nprint(accuracy(arr2,arr3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}